---
title: "One sample proportion test"
author: "Illarion  Jabine"
date: "02/04/2022"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)
```


# 1. Required packages:


* ggstatsplot: 
creates graphics with details from statistical tests included in the plots themselves. 
It provides an easier syntax to generate information-rich plots for statistical analysis of continuous (violin plots, scatterplots, histograms, dot plots, dot-and-whisker plots) or categorical (pie and bar charts) data. 
Currently, it supports the most common types of statistical approaches and tests: parametric, nonparametric, robust, and Bayesian versions of t-test/ANOVA, correlation analyses, contingency table analysis, meta-analysis, and regression analyses.

```{r load libraries, message=FALSE, warning=FALSE}
library(ggstatsplot)
library(tidyverse)
```


# 2. Key terms and links
 * binomial test
 * chi-square goodness of fit test
 * expected frequencies (must be > 5)
 * observed frequencies
 * multinomial probability distribution
http://www.sthda.com/english/wiki/comparing-proportions-in-r
https://indrajeetpatil.github.io/ggstatsplot/reference/ggbarstats.html
To combine bar or pie charts with proportion tests use ggbarstats() from ggstatsplot package.
# 3. Types of the test of proportions
We have to distinguish several types of proportion tests:
 1. One sample proportion test (compare one sample with a target):
     Binary outcome categories
     Three or more outcome categories
 2. Two sample proportion tests (compare two samples with each other):
    Binary outcome categories
    Three or more outcome categories
 3. Three or more population proportion tests (compare more than two samples):
    Binary outcome categories
    Three or more outcome categories     

## 3.1 One sample proportion test (compare one sample with a target)

### 3.1.1 Binary outcome categories

Source (https://support.minitab.com/en-us/minitab/20/help-and-how-to/statistics/basic-statistics/how-to/1-proportion/before-you-start/overview/)

Use 1 Proportion to estimate a binomial population proportion and to compare the proportion to a target value or a reference value. 
Using this analysis, you can do the following when your data contain only two categories, such as pass/fail:
   1. Determine whether the population proportion differs from the hypothesized proportion that you specify.
   2. Calculate a range of values that is likely to include the population proportion.
For example, a marketing analyst wants to determine whether mailed advertisements that were sent to a random sample of households result in a response rate that is different from the national average of 6.5% (target value). 
If the proportion differs from the target value, the analyst can use the confidence interval to determine whether the difference is practically significant.
 % Defective vs. target
 Each item is classified into one of two categories, such as pass/fail or defective/nondefective. 
 You count the number of defective items and compare the percentage of defectives with a target percentage. 

It's important to know that each item in the sample should have the same chance of being defective. 
(source minitab)
To produce accurate results, each item in the sample should have the same chance of being defective as any other item in the sample. 
Therefore, the items in the sample should be collected under the same inputs and conditions, such as personnel, equipment, suppliers, or environment. 
For example, different machines that apply paint coatings may produce a different percentage of defective coatings. 
Therefore, you wouldn't want to collect samples from the different machines and treat them as if they were from a single machine. 
You should also avoid collecting samples over long periods of time, which can increase the likelihood of process changes that can alter the defective rate. 

Statistical test to use in R: prop.test() and/or binom.test()
URL: http://www.sthda.com/english/wiki/one-proportion-z-test-in-r
https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Book%3A_Statistics_Using_Technology_(Kozak)/07%3A_One-Sample_Inference/7.02%3A_One-Sample_Proportion_Test


Example:
Engineers examine a sample of bolts for severe cracks that make the bolts unusable. 
They record the number of bolts that are inspected and the number of bolts that are rejected. 
The engineers want to determine whether the percentage of defective bolts is less than 0.2%.

Example 2:
According to the February 2008 Federal Trade Commission report on consumer fraud and identity theft, 23% of all complaints in 2007 were for identity theft. 
In that year, Arkansas had 1,601 complaints of identity theft out of 3,482 consumer complaints ("Consumer fraud and," 2008). 
Does this data provide enough evidence to show that Arkansas had a higher proportion of identity theft than 23%? 
Test at the 5% level.

Solution:
1. Parameters
x = number of complaints of identity theft in Arkansas = 1601 
p = proportion of identity theft in population = 0.23
n = a simple random sample of size n  = 3482

2. Hypothesis
Null hypothesis (H0): There is no significant difference between the observed and the expected value.
Alternative hypothesis (Ha): There is a significant difference between the observed and the expected value.
Ho:p=0.23 
HA:p>0.23
α=0.05

R code:
```{r}
prop_res <- prop.test(x = 1601, n = 3482, p = 0.23,alternative = "greater",correct = TRUE)
prop_res

# using binom test:
binom.test(x = 1601, n = 3482, p = 0.23,alternative = "greater")
```
3. Conclusion:
Calculated p value is less than 0.05 => we reject H0. There is enough evidence to show that the proportion of Arkansas has a higher proportion of identity theft than 23%.



### 3.1.2 Three or more outcome categories

Percents in each outcome category vs. target
chi-square goodness of fit test is used to compare the observed distribution to an expected distribution, in a situation where we have three or more categories in a discrete data. 
In other words, it compares multiple observed proportions to expected probabilities.

Source (minitab)
Each item is classified into one of three or more outcome categories, such as poor, fair, good, and excellent. 
You count the number of items in each category and compare the percentage in each category with its target percentage. 

Statistical hypotheses
Null hypothesis (H0): There is no significant difference between the observed and the expected value.
Alternative hypothesis (Ha): There is a significant difference between the observed and the expected value

Example:
Analysts at a finance department sample overdue invoices and categorize them by the number of days that payment is overdue: 15 days or less, 16–30 days, or 31 days or more. 
They want to determine whether the percentage of overdue invoices in each category differs from its target percentage.

Let's say he collected a sample of 100 invoices.
For example, the target (expected) proportion might be the following: 
15 days: 50%
16-30 days: 40%
31 days and more: 10%

The observed proportion:
15 days: 40%
16-30 days: 40%
31 days and more: 20%

The research question is: We want to know,if there is any significant difference between the observed proportions and the expected proportions.
So, 
H0: pA = .50, pB = .40, and pC = .10
Ha: The population proportions are not pA = .50, pB = .40, and pC = .10

Like other chi-square tests, the goodness of fit test is based on:
a comparison of observed frequencies with the expected frequencies under the assumption that the null hypothesis is true.
Whether the differences between the observed and expected frequencies are “large” or “small” is a question answered with the aid of the chi-square test statistic.

Important: 
 1. The expected frequencies must all be 5 or more for the chi-square test to be valid.
 2. The test for goodness of fit is always a one-tailed test with the rejection occurring in the upper tail of the chi-square distribution.
 The null hypothesis rejected if the differences between the observed and expected frequencies are large.
Rejection rule:
  1. p-value approach: Reject H0 if p-value <= α
  2. Critical value approach: Reject H0 if chi(stat) >= chi(α)

Statistical test to use in R: chisq.test() - Chi-Square Goodness-of-fit test
URL: http://www.sthda.com/english/wiki/chi-square-goodness-of-fit-test-in-r
     https://www.r-bloggers.com/2015/01/goodness-of-fit-test-in-r/
    https://indrajeetpatil.github.io/ggstatsplot/articles/web_only/ggpiestats.html#goodness-of-fit-with-ggpiestats

```{r}
invoices <- c(40,40,20)
x_squared_test <- chisq.test(x = invoices, p = c(0.5,0.4,0.1))
x_squared_test
```
Conclusion:
The p-value of the test is less than the significance level alpha = 0.05 => we reject H0. 
We can conclude that the significant difference between the observed and the expected value.
